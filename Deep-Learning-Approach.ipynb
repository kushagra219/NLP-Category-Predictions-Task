{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dropout, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "embedding_dim = 16\n",
    "max_length = 500\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "training_size = 35000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>primary_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alisha solid woman cycling short cotton lycra ...</td>\n",
       "      <td>Clothing\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fabhomedecor fabric double sofa bed finish col...</td>\n",
       "      <td>Furniture\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>belly sandal wedge heel casuals belly price ma...</td>\n",
       "      <td>Footwear\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description primary_category\n",
       "0  alisha solid woman cycling short cotton lycra ...       Clothing\\n\n",
       "1  fabhomedecor fabric double sofa bed finish col...      Furniture\\n\n",
       "2  belly sandal wedge heel casuals belly price ma...       Footwear\\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('corpus.txt', 'r', encoding='utf-8') as file:\n",
    "    description = list(file.readlines())\n",
    "    \n",
    "with open('final_categories.txt', 'rt') as file:\n",
    "    primary_category = list(file.readlines())\n",
    "    \n",
    "df = pd.DataFrame()\n",
    "df[\"description\"] = description \n",
    "df[\"primary_category\"] = primary_category\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>primary_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alisha solid woman cycling short cotton lycra ...</td>\n",
       "      <td>Clothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fabhomedecor fabric double sofa bed finish col...</td>\n",
       "      <td>Furniture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>belly sandal wedge heel casuals belly price ma...</td>\n",
       "      <td>Footwear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description primary_category\n",
       "0  alisha solid woman cycling short cotton lycra ...         Clothing\n",
       "1  fabhomedecor fabric double sofa bed finish col...        Furniture\n",
       "2  belly sandal wedge heel casuals belly price ma...         Footwear"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"description\"] = df[\"description\"].str.replace('\\n', '') \n",
    "df[\"primary_category\"] = df[\"primary_category\"].str.replace('\\n', '')\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15732,)\n",
      "(3934,)\n",
      "(15732,)\n",
      "(3934,)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(df[\"description\"])\n",
    "y = np.array(df[\"primary_category\"])\n",
    "\n",
    "training_sentences, testing_sentences, training_labels, testing_labels = train_test_split(X, y, test_size=0.20, random_state=73)\n",
    "\n",
    "print(training_sentences.shape)\n",
    "print(testing_sentences.shape)\n",
    "print(training_labels.shape)\n",
    "print(testing_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3, 20,  5, ..., 13, 26, 17])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "training_labels = le.fit_transform(training_labels)\n",
    "\n",
    "training_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17,  6,  3, ..., 24, 17, 13])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_labels = le.transform(testing_labels)\n",
    "\n",
    "testing_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15732\n",
      "[[1940  232 2460 ...    0    0    0]\n",
      " [  13    1  728 ...    0    0    0]\n",
      " [2599   10  184 ...    0    0    0]\n",
      " ...\n",
      " [2766  401  223 ...    0    0    0]\n",
      " [ 975  126   94 ...    0    0    0]\n",
      " [ 233   58   24 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "print(len(training_sequences))\n",
    "print(training_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_padded = np.array(training_padded)\n",
    "training_labels = np.array(training_labels)\n",
    "testing_padded = np.array(testing_padded)\n",
    "testing_labels = np.array(testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='softmax')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 16)           160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 24)                408       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 160,433\n",
      "Trainable params: 160,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "492/492 - 3s - loss: -2.9233e+02 - accuracy: 0.0230 - val_loss: -1.2199e+03 - val_accuracy: 0.0308\n",
      "Epoch 2/10\n",
      "492/492 - 1s - loss: -4.5135e+03 - accuracy: 0.0230 - val_loss: -9.5691e+03 - val_accuracy: 0.0308\n",
      "Epoch 3/10\n",
      "492/492 - 1s - loss: -1.8412e+04 - accuracy: 0.0230 - val_loss: -2.9817e+04 - val_accuracy: 0.0308\n",
      "Epoch 4/10\n",
      "492/492 - 1s - loss: -4.5574e+04 - accuracy: 0.0230 - val_loss: -6.4707e+04 - val_accuracy: 0.0308\n",
      "Epoch 5/10\n",
      "492/492 - 1s - loss: -8.8291e+04 - accuracy: 0.0230 - val_loss: -1.1614e+05 - val_accuracy: 0.0308\n",
      "Epoch 6/10\n",
      "492/492 - 2s - loss: -1.4827e+05 - accuracy: 0.0230 - val_loss: -1.8559e+05 - val_accuracy: 0.0308\n",
      "Epoch 7/10\n",
      "492/492 - 1s - loss: -2.2656e+05 - accuracy: 0.0230 - val_loss: -2.7390e+05 - val_accuracy: 0.0308\n",
      "Epoch 8/10\n",
      "492/492 - 1s - loss: -3.2412e+05 - accuracy: 0.0230 - val_loss: -3.8225e+05 - val_accuracy: 0.0308\n",
      "Epoch 9/10\n",
      "492/492 - 1s - loss: -4.4196e+05 - accuracy: 0.0230 - val_loss: -5.1138e+05 - val_accuracy: 0.0308\n",
      "Epoch 10/10\n",
      "492/492 - 2s - loss: -5.8094e+05 - accuracy: 0.0230 - val_loss: -6.6233e+05 - val_accuracy: 0.0308\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "history = model.fit(training_padded, training_labels, epochs=num_epochs, \n",
    "                    validation_data=(testing_padded, testing_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.callbacks.History object at 0x0000023B47313670>\n"
     ]
    }
   ],
   "source": [
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 500) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": " Cast string to float is not supported\n\t [[node sequential_3/Cast (defined at <ipython-input-38-17486c8be718>:1) ]] [Op:__inference_predict_function_27545]\n\nFunction call stack:\npredict_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-17486c8be718>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"style foot belly ballerina shoe ballerina flat style foot belly price ballet shoe fit perfectly casual party wear specification style foot belly general occasion casual ideal woman shoe heel height inch outer material color black slipper\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1627\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1629\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1630\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    892\u001b[0m               *args, **kwds)\n\u001b[0;32m    893\u001b[0m       \u001b[1;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 894\u001b[1;33m       return self._concrete_stateful_fn._call_flat(\n\u001b[0m\u001b[0;32m    895\u001b[0m           filtered_flat_args, self._concrete_stateful_fn.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnimplementedError\u001b[0m:  Cast string to float is not supported\n\t [[node sequential_3/Cast (defined at <ipython-input-38-17486c8be718>:1) ]] [Op:__inference_predict_function_27545]\n\nFunction call stack:\npredict_function\n"
     ]
    }
   ],
   "source": [
    "model.predict([[\"style foot belly ballerina shoe ballerina flat style foot belly price ballet shoe fit perfectly casual party wear specification style foot belly general occasion casual ideal woman shoe heel height inch outer material color black slipper\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TFIDF(X_train, X_test, MAX_NB_WORDS=75000):\n",
    "    tfidf_vec = TfidfVectorizer(max_features = MAX_NB_WORDS)\n",
    "    X_train = tfidf_vec.fit_transform(X_train).toarray()\n",
    "    X_test = tfidf_vec.transform(X_test).toarray()\n",
    "    print(\"tf-idf with\", str(np.array(X_train).shape[1]), \"features\")\n",
    "    return (X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Build_Model_DNN_Text(shape, nClasses, dropout=0.5):\n",
    "    \"\"\"\n",
    "    buildModel_DNN_Tex(shape, nClasses,dropout)\n",
    "    Build Deep neural networks Model for text classification\n",
    "    Shape is input feature space\n",
    "    nClasses is number of classes\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    node = 512 # number of nodes\n",
    "    nLayers = 4 # number of  hidden layer\n",
    "    model.add(Dense(node,input_dim=shape,activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    for i in range(0,nLayers):\n",
    "        model.add(Dense(node, input_dim=node, activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(nClasses, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf-idf with 13595 features\n",
      "Epoch 1/50\n",
      "123/123 - 10s - loss: 1.6849 - accuracy: 0.4729 - val_loss: 0.9535 - val_accuracy: 0.6769\n",
      "Epoch 2/50\n",
      "123/123 - 9s - loss: 0.6458 - accuracy: 0.7916 - val_loss: 0.3558 - val_accuracy: 0.9026\n",
      "Epoch 3/50\n",
      "123/123 - 9s - loss: 0.3112 - accuracy: 0.9006 - val_loss: 0.2966 - val_accuracy: 0.9164\n",
      "Epoch 4/50\n",
      "123/123 - 9s - loss: 0.2084 - accuracy: 0.9305 - val_loss: 0.2407 - val_accuracy: 0.9385\n",
      "Epoch 5/50\n",
      "123/123 - 9s - loss: 0.1532 - accuracy: 0.9512 - val_loss: 0.2381 - val_accuracy: 0.9459\n",
      "Epoch 6/50\n",
      "123/123 - 9s - loss: 0.1167 - accuracy: 0.9647 - val_loss: 0.1874 - val_accuracy: 0.9583\n",
      "Epoch 7/50\n",
      "123/123 - 10s - loss: 0.0861 - accuracy: 0.9723 - val_loss: 0.1863 - val_accuracy: 0.9642\n",
      "Epoch 8/50\n",
      "123/123 - 10s - loss: 0.0787 - accuracy: 0.9762 - val_loss: 0.1801 - val_accuracy: 0.9652\n",
      "Epoch 9/50\n",
      "123/123 - 9s - loss: 0.0656 - accuracy: 0.9808 - val_loss: 0.1874 - val_accuracy: 0.9682\n",
      "Epoch 10/50\n",
      "123/123 - 9s - loss: 0.0487 - accuracy: 0.9865 - val_loss: 0.1896 - val_accuracy: 0.9677\n",
      "Epoch 11/50\n",
      "123/123 - 9s - loss: 0.0477 - accuracy: 0.9865 - val_loss: 0.1846 - val_accuracy: 0.9672\n",
      "Epoch 12/50\n",
      "123/123 - 9s - loss: 0.0439 - accuracy: 0.9874 - val_loss: 0.1875 - val_accuracy: 0.9672\n",
      "Epoch 13/50\n",
      "123/123 - 9s - loss: 0.0379 - accuracy: 0.9900 - val_loss: 0.1909 - val_accuracy: 0.9695\n",
      "Epoch 14/50\n",
      "123/123 - 10s - loss: 0.0300 - accuracy: 0.9915 - val_loss: 0.2050 - val_accuracy: 0.9667\n",
      "Epoch 15/50\n",
      "123/123 - 10s - loss: 0.0295 - accuracy: 0.9915 - val_loss: 0.2071 - val_accuracy: 0.9692\n",
      "Epoch 16/50\n",
      "123/123 - 10s - loss: 0.0312 - accuracy: 0.9914 - val_loss: 0.2058 - val_accuracy: 0.9690\n",
      "Epoch 17/50\n",
      "123/123 - 10s - loss: 0.0311 - accuracy: 0.9921 - val_loss: 0.1971 - val_accuracy: 0.9654\n",
      "Epoch 18/50\n",
      "123/123 - 10s - loss: 0.0194 - accuracy: 0.9951 - val_loss: 0.2077 - val_accuracy: 0.9690\n",
      "Epoch 19/50\n",
      "123/123 - 10s - loss: 0.0212 - accuracy: 0.9946 - val_loss: 0.1980 - val_accuracy: 0.9695\n",
      "Epoch 20/50\n",
      "123/123 - 10s - loss: 0.0235 - accuracy: 0.9932 - val_loss: 0.2145 - val_accuracy: 0.9687\n",
      "Epoch 21/50\n",
      "123/123 - 10s - loss: 0.0217 - accuracy: 0.9947 - val_loss: 0.2088 - val_accuracy: 0.9692\n",
      "Epoch 22/50\n",
      "123/123 - 10s - loss: 0.0185 - accuracy: 0.9952 - val_loss: 0.2066 - val_accuracy: 0.9682\n",
      "Epoch 23/50\n",
      "123/123 - 10s - loss: 0.0154 - accuracy: 0.9949 - val_loss: 0.2158 - val_accuracy: 0.9718\n",
      "Epoch 24/50\n",
      "123/123 - 10s - loss: 0.0168 - accuracy: 0.9957 - val_loss: 0.2191 - val_accuracy: 0.9708\n",
      "Epoch 25/50\n",
      "123/123 - 10s - loss: 0.0157 - accuracy: 0.9955 - val_loss: 0.2544 - val_accuracy: 0.9692\n",
      "Epoch 26/50\n",
      "123/123 - 9s - loss: 0.0143 - accuracy: 0.9959 - val_loss: 0.2424 - val_accuracy: 0.9708\n",
      "Epoch 27/50\n",
      "123/123 - 9s - loss: 0.0176 - accuracy: 0.9954 - val_loss: 0.2305 - val_accuracy: 0.9703\n",
      "Epoch 28/50\n",
      "123/123 - 10s - loss: 0.0172 - accuracy: 0.9955 - val_loss: 0.2200 - val_accuracy: 0.9725\n",
      "Epoch 29/50\n",
      "123/123 - 9s - loss: 0.0128 - accuracy: 0.9964 - val_loss: 0.2305 - val_accuracy: 0.9723\n",
      "Epoch 30/50\n",
      "123/123 - 10s - loss: 0.0155 - accuracy: 0.9961 - val_loss: 0.2422 - val_accuracy: 0.9731\n",
      "Epoch 31/50\n",
      "123/123 - 10s - loss: 0.0137 - accuracy: 0.9968 - val_loss: 0.2309 - val_accuracy: 0.9731\n",
      "Epoch 32/50\n",
      "123/123 - 10s - loss: 0.0156 - accuracy: 0.9969 - val_loss: 0.2387 - val_accuracy: 0.9725\n",
      "Epoch 33/50\n",
      "123/123 - 9s - loss: 0.0130 - accuracy: 0.9968 - val_loss: 0.2534 - val_accuracy: 0.9715\n",
      "Epoch 34/50\n",
      "123/123 - 10s - loss: 0.0126 - accuracy: 0.9970 - val_loss: 0.2435 - val_accuracy: 0.9713\n",
      "Epoch 35/50\n",
      "123/123 - 10s - loss: 0.0114 - accuracy: 0.9973 - val_loss: 0.3081 - val_accuracy: 0.9698\n",
      "Epoch 36/50\n",
      "123/123 - 9s - loss: 0.0102 - accuracy: 0.9975 - val_loss: 0.2454 - val_accuracy: 0.9728\n",
      "Epoch 37/50\n",
      "123/123 - 10s - loss: 0.0168 - accuracy: 0.9965 - val_loss: 0.2513 - val_accuracy: 0.9703\n",
      "Epoch 38/50\n",
      "123/123 - 9s - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.2630 - val_accuracy: 0.9703\n",
      "Epoch 39/50\n",
      "123/123 - 9s - loss: 0.0114 - accuracy: 0.9971 - val_loss: 0.2594 - val_accuracy: 0.9687\n",
      "Epoch 40/50\n",
      "123/123 - 10s - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.2891 - val_accuracy: 0.9731\n",
      "Epoch 41/50\n",
      "123/123 - 9s - loss: 0.0181 - accuracy: 0.9964 - val_loss: 0.2704 - val_accuracy: 0.9692\n",
      "Epoch 42/50\n",
      "123/123 - 10s - loss: 0.0163 - accuracy: 0.9961 - val_loss: 0.2555 - val_accuracy: 0.9703\n",
      "Epoch 43/50\n",
      "123/123 - 9s - loss: 0.0164 - accuracy: 0.9966 - val_loss: 0.2407 - val_accuracy: 0.9708\n",
      "Epoch 44/50\n",
      "123/123 - 9s - loss: 0.0089 - accuracy: 0.9975 - val_loss: 0.2493 - val_accuracy: 0.9703\n",
      "Epoch 45/50\n",
      "123/123 - 10s - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.2458 - val_accuracy: 0.9718\n",
      "Epoch 46/50\n",
      "123/123 - 10s - loss: 0.0119 - accuracy: 0.9975 - val_loss: 0.2446 - val_accuracy: 0.9720\n",
      "Epoch 47/50\n",
      "123/123 - 10s - loss: 0.0077 - accuracy: 0.9978 - val_loss: 0.2706 - val_accuracy: 0.9715\n",
      "Epoch 48/50\n",
      "123/123 - 10s - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.2587 - val_accuracy: 0.9723\n",
      "Epoch 49/50\n",
      "123/123 - 9s - loss: 0.0088 - accuracy: 0.9978 - val_loss: 0.2739 - val_accuracy: 0.9715\n",
      "Epoch 50/50\n",
      "123/123 - 9s - loss: 0.0095 - accuracy: 0.9978 - val_loss: 0.2640 - val_accuracy: 0.9738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kusha\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       193\n",
      "           1       0.96      0.89      0.92       121\n",
      "           2       0.95      0.93      0.94        43\n",
      "           3       0.96      0.96      0.96       135\n",
      "           4       0.78      0.93      0.85        15\n",
      "           5       1.00      0.99      0.99      1218\n",
      "           6       0.96      0.94      0.95       126\n",
      "           7       1.00      1.00      1.00         1\n",
      "           8       1.00      0.99      0.99       259\n",
      "           9       1.00      1.00      1.00        39\n",
      "          10       0.57      0.80      0.67        10\n",
      "          11       1.00      0.86      0.92         7\n",
      "          12       0.67      0.50      0.57         4\n",
      "          13       0.98      0.99      0.99       185\n",
      "          14       0.50      0.67      0.57         3\n",
      "          15       0.98      0.99      0.98       130\n",
      "          16       0.45      0.94      0.61        16\n",
      "          17       1.00      1.00      1.00       669\n",
      "          18       0.96      0.96      0.96       133\n",
      "          19       0.97      0.96      0.97       234\n",
      "          20       0.91      0.84      0.87        80\n",
      "          21       0.80      0.89      0.84         9\n",
      "          22       0.95      0.91      0.93        43\n",
      "          23       1.00      1.00      1.00        10\n",
      "          24       0.96      0.96      0.96        79\n",
      "          25       0.82      0.92      0.87        61\n",
      "          26       0.99      1.00      1.00       107\n",
      "          27       0.40      0.50      0.44         4\n",
      "\n",
      "    accuracy                           0.97      3934\n",
      "   macro avg       0.88      0.90      0.88      3934\n",
      "weighted avg       0.98      0.97      0.97      3934\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_tfidf, X_test_tfidf = TFIDF(training_sentences, testing_sentences)\n",
    "\n",
    "model_DNN = Build_Model_DNN_Text(X_train_tfidf.shape[1], 28)\n",
    "history = model_DNN.fit(X_train_tfidf, training_labels,\n",
    "                              validation_data=(X_test_tfidf, testing_labels),\n",
    "                              epochs=100,\n",
    "                              batch_size=128,\n",
    "                              verbose=2)\n",
    "\n",
    "predicted = model_DNN.predict_classes(X_test_tfidf)\n",
    "print(metrics.classification_report(testing_labels, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1df2e18b3dff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# summarize history for accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
