{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import pickle\n",
    "from IPython.display import display\n",
    "\n",
    "# data manipulation & vizualization libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, \\\n",
    "AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, StackingClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedStratifiedKFold, cross_validate\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, \\\n",
    "f1_score, recall_score, roc_auc_score, precision_score, make_scorer\n",
    "from sklearn.neighbors import NearestCentroid, KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>primary_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alisha solid woman cycling short cotton lycra ...</td>\n",
       "      <td>Clothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fabhomedecor fabric double sofa bed finish col...</td>\n",
       "      <td>Furniture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>belly sandal wedge heel casuals belly price ma...</td>\n",
       "      <td>Footwear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description primary_category\n",
       "0  alisha solid woman cycling short cotton lycra ...         Clothing\n",
       "1  fabhomedecor fabric double sofa bed finish col...        Furniture\n",
       "2  belly sandal wedge heel casuals belly price ma...         Footwear"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the corpus of cleaned data and asigning each column to the new dataframe\n",
    "\n",
    "with open('clean-dataset/corpus.txt', 'rt', encoding='utf-8') as file:\n",
    "    description = list(file.readlines())\n",
    "    \n",
    "with open('clean-dataset/final-categories.txt', 'rt') as file:\n",
    "    primary_category = list(file.readlines())\n",
    "    \n",
    "df = pd.DataFrame()\n",
    "df[\"description\"] = description \n",
    "df[\"primary_category\"] = primary_category\n",
    "df[\"description\"] = df[\"description\"].str.replace('\\n', '') \n",
    "df[\"primary_category\"] = df[\"primary_category\"].str.replace('\\n', '')\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total no of words in desciption column \n",
    "\n",
    "df[\"description\"].str.split().str.len().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15732,)\n",
      "(15732,)\n",
      "(3934,)\n",
      "(3934,)\n"
     ]
    }
   ],
   "source": [
    "# splitting the X, y into X_train, X_test, y_train & y_test\n",
    "\n",
    "X = np.array(df[\"description\"])\n",
    "y = np.array(df[\"primary_category\"])\n",
    "\n",
    "# le = LabelEncoder()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=73)\n",
    "# y_train = le.fit_transform(y_train)\n",
    "# y_test = le.transform(y_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction Functions\n",
    "\n",
    "* Count Vectorizer\n",
    "* TF-IDF Vectorizer\n",
    "* Pipeline of Count Vectorizer followed by TF-IDF Vectorizer followed by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns X_train_features and X_test_features after applying CountVectorizer on both \n",
    "\n",
    "def CountVec(X_train, X_test):\n",
    "    count_vec = CountVectorizer()\n",
    "    X_train_features = count_vec.fit_transform(X_train)\n",
    "    X_test_features = count_vec.transform(X_test)\n",
    "    return (X_train_features, X_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns X_train_features and X_test_features after applying TFIDFVectorizer on both \n",
    "\n",
    "def TFIDF(X_train, X_test):\n",
    "    tfidf_vec = TfidfVectorizer()\n",
    "    X_train_features = tfidf_vec.fit_transform(X_train)\n",
    "    X_test_features = tfidf_vec.transform(X_test)\n",
    "    return (X_train_features, X_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a pipeline of CountVectorizer, followed by TFIDF Vectorizer and then followed by the ML model \n",
    "\n",
    "def CountVec_TFIDF_Pipeline(model):\n",
    "    return Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', model)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multinomial Naive Bayes Classifier with Count Vectorizer\n",
    "\n",
    "X_train_features, X_test_features = CountVec(X_train, X_test)\n",
    "clf = MultinomialNB(alpha = 0.01)\n",
    "clf.fit(X_train_features, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_features)\n",
    "print(y_pred)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "# print(classification_report(y_test, y_pred))\n",
    "# print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Beauty and Personal Care', 'Pens & Stationery', 'Clothing', ...,\n",
       "       'Home Decor & Festive Needs', 'Watches', 'Jewellery'], dtype='<U33')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = clf.predict(X_train_features)\n",
    "\n",
    "print(accuracy_score(y_train, y_train_pred))\n",
    "# print(classification_report(y_train, y_train_pred))\n",
    "# print(confusion_matrix(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9202181920839543\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha = 0.01)\n",
    "X_features = TfidfVectorizer().fit_transform(X)\n",
    "scores = cross_validate(clf, X_features, y, cv=5, return_train_score=False)\n",
    "print(np.mean(scores[\"test_score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.001)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multinomial Naive Bayes Algorithm with Tfidf Vectorizer\n",
    "\n",
    "X_train_features, X_test_features = TFIDF(X_train, X_test)\n",
    "clf = MultinomialNB(alpha = 0.001)\n",
    "clf.fit(X_train_features, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_features)\n",
    "print(y_pred)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "# print(classification_report(y_test, y_pred))\n",
    "# print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Beauty and Personal Care', 'Pens & Stationery', 'Clothing', ...,\n",
       "       'Home Decor & Festive Needs', 'Watches', 'Jewellery'], dtype='<U33')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = clf.predict(X_train_features)\n",
    "\n",
    "print(accuracy_score(y_train, y_train_pred))\n",
    "# print(classification_report(y_train, y_train_pred))\n",
    "# print(confusion_matrix(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9202181920839543\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha = 0.01)\n",
    "X_features = TfidfVectorizer().fit_transform(X)\n",
    "scores = cross_validate(clf, X_features, y, cv=5, return_train_score=False)\n",
    "print(np.mean(scores[\"test_score\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Classifier with Count Vectorizer\n",
    "\n",
    "X_train_features, X_test_features = CountVec(X_train, X_test)\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train_features, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_features)\n",
    "print(y_pred)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "# print(classification_report(y_test, y_pred))\n",
    "# print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = clf.predict(X_train_features)\n",
    "\n",
    "print(accuracy_score(y_train, y_train_pred))\n",
    "# print(classification_report(y_train, y_train_pred))\n",
    "# print(confusion_matrix(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC()\n",
    "X_features = CountVectorizer().fit_transform(X)\n",
    "scores = cross_validate(clf, X_features, y, cv=5, return_train_score=False)\n",
    "print(np.mean(scores[\"test_score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Classifier with Count Vectorizer\n",
    "\n",
    "X_train_features, X_test_features = TFIDF(X_train, X_test)\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train_features, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_features)\n",
    "print(y_pred)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "# print(classification_report(y_test, y_pred))\n",
    "# print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = clf.predict(X_train_features)\n",
    "\n",
    "print(accuracy_score(y_train, y_train_pred))\n",
    "# print(classification_report(y_train, y_train_pred))\n",
    "# print(confusion_matrix(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC()\n",
    "X_features = TfidfVectorizer().fit_transform(X)\n",
    "scores = cross_validate(clf, X_features, y, cv=5, return_train_score=False)\n",
    "print(np.mean(scores[\"test_score\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier with Count Vectorizer\n",
    "\n",
    "X_train_features, X_test_features = CountVec(X_train, X_test)\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train_features, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_features)\n",
    "print(y_pred)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "# print(classification_report(y_test, y_pred))\n",
    "# print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = clf.predict(X_train_features)\n",
    "\n",
    "print(accuracy_score(y_train, y_train_pred))\n",
    "# print(classification_report(y_train, y_train_pred))\n",
    "# print(confusion_matrix(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "X_features = CountVectorizer().fit_transform(X)\n",
    "scores = cross_validate(clf, X_features, y, cv=5, return_train_score=False)\n",
    "print(np.mean(scores[\"test_score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier with TF-IDF Vectorizer\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "X_train_features, X_test_features = TFIDF(X_train, X_test)\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train_features, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_features)\n",
    "print(y_pred)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "# print(classification_report(y_test, y_pred))\n",
    "# print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = clf.predict(X_train_features)\n",
    "\n",
    "print(accuracy_score(y_train, y_train_pred))\n",
    "# print(classification_report(y_train, y_train_pred))\n",
    "# print(confusion_matrix(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "X_features = TfidfVectorizer().fit_transform(X)\n",
    "scores = cross_validate(clf, X_features, y, cv=5, return_train_score=False)\n",
    "print(np.mean(scores[\"test_score\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighbours Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', KNeighborsClassifier(n_neighbors=5)),\n",
    "                     ])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "# print(classification_report(y_test, y_pred))\n",
    "# print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = clf.predict(X_train)\n",
    "\n",
    "print(accuracy_score(y_train, y_train_pred))\n",
    "# print(classification_report(y_train, y_train_pred))\n",
    "# print(confusion_matrix(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', KNeighborsClassifier()),\n",
    "                     ])\n",
    "scores = cross_validate(clf, X, y, cv=5, return_train_score=False)\n",
    "print(np.mean(scores[\"test_score\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jewellery' 'Computers' 'Beauty and Personal Care' ... 'Tools & Hardware'\n",
      " 'Jewellery' 'Home Decor & Festive Needs']\n",
      "0.9572953736654805\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', GradientBoostingClassifier(n_estimators=100)),\n",
    "                ])\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "# print(classification_report(y_test, y_pred))\n",
    "# print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9987287058225274\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = clf.predict(X_train)\n",
    "\n",
    "print(accuracy_score(y_train, y_train_pred))\n",
    "# print(classification_report(y_train, y_train_pred))\n",
    "# print(confusion_matrix(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9080142721029715\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', GradientBoostingClassifier(n_estimators=100)),\n",
    "                     ])\n",
    "scores = cross_validate(clf, X, y, cv=5, return_train_score=False)\n",
    "print(np.mean(scores[\"test_score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
