{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import pickle\n",
    "import joblib\n",
    "from IPython.display import display\n",
    "\n",
    "# data manipulation & vizualization libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, \\\n",
    "AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, StackingClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedStratifiedKFold, cross_validate\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, \\\n",
    "f1_score, recall_score, roc_auc_score, precision_score, make_scorer\n",
    "from sklearn.neighbors import NearestCentroid, KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>primary_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alisha solid woman cycling short cotton lycra ...</td>\n",
       "      <td>Clothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fabhomedecor fabric double sofa bed finish col...</td>\n",
       "      <td>Furniture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>belly sandal wedge heel casuals belly price ma...</td>\n",
       "      <td>Footwear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description primary_category\n",
       "0  alisha solid woman cycling short cotton lycra ...         Clothing\n",
       "1  fabhomedecor fabric double sofa bed finish col...        Furniture\n",
       "2  belly sandal wedge heel casuals belly price ma...         Footwear"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the corpus of cleaned data and asigning each column to the new dataframe\n",
    "\n",
    "with open('clean-dataset/corpus.txt', 'rt', encoding='utf-8') as file:\n",
    "    description = list(file.readlines())\n",
    "    \n",
    "with open('clean-dataset/final-categories.txt', 'rt') as file:\n",
    "    primary_category = list(file.readlines())\n",
    "    \n",
    "df = pd.DataFrame()\n",
    "df[\"description\"] = description \n",
    "df[\"primary_category\"] = primary_category\n",
    "df[\"description\"] = df[\"description\"].str.replace('\\n', '') \n",
    "df[\"primary_category\"] = df[\"primary_category\"].str.replace('\\n', '')\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15732,)\n",
      "(15732,)\n",
      "(3934,)\n",
      "(3934,)\n"
     ]
    }
   ],
   "source": [
    "# splitting the X, y into X_train, X_test, y_train & y_test\n",
    "\n",
    "X = np.array(df[\"description\"])\n",
    "y = np.array(df[\"primary_category\"])\n",
    "\n",
    "# le = LabelEncoder()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=73)\n",
    "# y_train = le.fit_transform(y_train)\n",
    "# y_test = le.transform(y_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XLNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:14:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['Jewellery' 'Computers' 'Beauty and Personal Care' ... 'Tools & Hardware'\n",
      " 'Jewellery' 'Home Decor & Festive Needs']\n",
      "0.974580579562786\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "                       Automotive       0.96      0.97      0.97       193\n",
      "                        Baby Care       0.96      0.90      0.93       121\n",
      "            Bags, Wallets & Belts       0.98      0.95      0.96        43\n",
      "         Beauty and Personal Care       0.96      0.96      0.96       135\n",
      "            Cameras & Accessories       1.00      0.80      0.89        15\n",
      "                         Clothing       0.99      1.00      1.00      1218\n",
      "                        Computers       0.92      0.96      0.94       126\n",
      "                          Eyewear       1.00      1.00      1.00         1\n",
      "                         Footwear       1.00      1.00      1.00       259\n",
      "                        Furniture       1.00      1.00      1.00        39\n",
      "                           Gaming       0.62      0.80      0.70        10\n",
      "Health & Personal Care Appliances       1.00      0.86      0.92         7\n",
      "                   Home & Kitchen       0.75      0.75      0.75         4\n",
      "       Home Decor & Festive Needs       0.95      0.97      0.96       185\n",
      "               Home Entertainment       0.50      0.33      0.40         3\n",
      "                  Home Furnishing       0.98      0.99      0.99       130\n",
      "                 Home Improvement       0.94      1.00      0.97        16\n",
      "                        Jewellery       1.00      1.00      1.00       669\n",
      "                 Kitchen & Dining       0.91      0.96      0.94       133\n",
      "            Mobiles & Accessories       0.97      0.98      0.97       234\n",
      "                Pens & Stationery       0.90      0.78      0.83        80\n",
      "                     Pet Supplies       1.00      0.78      0.88         9\n",
      "                 Sports & Fitness       1.00      0.93      0.96        43\n",
      "                       Sunglasses       1.00      1.00      1.00        10\n",
      "                 Tools & Hardware       0.96      0.95      0.96        79\n",
      "           Toys & School Supplies       0.81      0.89      0.84        61\n",
      "                          Watches       1.00      1.00      1.00       107\n",
      "                           eBooks       0.00      0.00      0.00         4\n",
      "\n",
      "                         accuracy                           0.97      3934\n",
      "                        macro avg       0.89      0.88      0.88      3934\n",
      "                     weighted avg       0.97      0.97      0.97      3934\n",
      "\n",
      "[[ 188    0    0    0    0    2    2    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    1    0    0    0    0    0    0    0    0]\n",
      " [   0  109    0    2    0    3    0    0    0    0    0    0    0    2\n",
      "     0    1    0    0    0    0    0    0    0    0    1    3    0    0]\n",
      " [   0    0   41    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    1    0    0    0    0    1    0    0]\n",
      " [   1    0    0  130    0    1    0    0    0    0    0    0    0    1\n",
      "     0    0    0    0    0    0    1    0    0    0    1    0    0    0]\n",
      " [   1    0    0    0   12    0    2    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    3    0    0    0 1213    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    2    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0  121    0    0    0    2    0    0    0\n",
      "     0    0    0    0    0    3    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    1    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    1    0  258    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0   39    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    1    0    0    0    8    0    0    0\n",
      "     0    0    0    0    0    0    1    0    0    0    0    0    0    0]\n",
      " [   1    0    0    0    0    0    0    0    0    0    0    6    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    1    0    0    0    0    0    3    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   1    1    0    1    0    0    0    0    0    0    0    0    1  179\n",
      "     0    0    0    0    1    0    0    0    0    0    1    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    1    0    0    0\n",
      "     1    0    0    0    0    1    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0  129    0    0    1    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0   16    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    1    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0  668    0    0    0    0    0    0    0    0    0    0]\n",
      " [   1    0    0    1    0    0    0    0    0    0    0    0    0    1\n",
      "     1    0    0    0  128    1    0    0    0    0    0    0    0    0]\n",
      " [   1    0    0    0    0    0    2    0    0    0    2    0    0    0\n",
      "     0    0    0    0    0  229    0    0    0    0    0    0    0    0]\n",
      " [   0    0    1    1    0    0    1    0    0    0    0    0    0    3\n",
      "     0    0    0    1    2    0   62    0    0    0    0    9    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    1\n",
      "     0    0    0    0    1    0    0    7    0    0    0    0    0    0]\n",
      " [   0    1    0    0    0    1    1    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0   40    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0   10    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    1\n",
      "     0    1    1    0    0    0    1    0    0    0   75    0    0    0]\n",
      " [   2    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    2    0    3    0    0    0    0   54    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0  107    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    3    1    0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([('vect', CountVectorizer()),\n",
    "#                 ('tfidf', TfidfTransformer()),\n",
    "                ('clf', XGBClassifier()),\n",
    "                ])\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(clf, 'trained-models/xgboost.pkl')\n",
    "# clf = joblib.load('trained-models/gradient-boosting.pkl') \n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9977116704805492\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = clf.predict(X_train)\n",
    "\n",
    "print(accuracy_score(y_train, y_train_pred))\n",
    "# print(classification_report(y_train, y_train_pred))\n",
    "# print(confusion_matrix(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kusha\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:25:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:26:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([('vect', CountVectorizer()),\n",
    "#                      ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', XGBClassifier()),\n",
    "                     ])\n",
    "scores = cross_validate(clf, X, y, cv=5, return_train_score=False)\n",
    "print(np.mean(scores[\"test_score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
